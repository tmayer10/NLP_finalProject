{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Define the problem \\\n",
    "Preprocess the data \\\n",
    "Extract features \\\n",
    "Prepare the data for NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import neccesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot --quiet\n",
    "!pip install gensim --quiet\n",
    "!pip install tensorflow-datasets --quiet\n",
    "!pip install tensorflow-text --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"../dataset/tagged_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1962-houston_oilers-dallas_texans.txt</th>\n",
       "      <th>1969-chicago_bears-green_bay_packers.txt</th>\n",
       "      <th>1969-cleveland_browns-minnesota_vikings-1.txt</th>\n",
       "      <th>1969-cleveland_browns-minnesota_vikings.txt</th>\n",
       "      <th>1969-new_york_jets-baltimore_colts.txt</th>\n",
       "      <th>1970-baltimore_colts-kansas_city_chiefs.txt</th>\n",
       "      <th>1970-cleveland_browns-new_york_jets.txt</th>\n",
       "      <th>1970-dallas_cowboys-detroit_lions.txt</th>\n",
       "      <th>1970-kansas_city_chiefs-baltimore_colts.txt</th>\n",
       "      <th>1970-los_angeles_rams-minnesota_vikings-1.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-tampa_bay_buccaneers-dallas_cowboys.txt</th>\n",
       "      <th>2018-tampa_bay_buccaneers-detroit_lions.txt</th>\n",
       "      <th>2018-tennessee_titans-green_bay_packers.txt</th>\n",
       "      <th>2018-tennessee_titans-minnesota_vikings.txt</th>\n",
       "      <th>2018-tennessee_titans-pittsburgh_steelers.txt</th>\n",
       "      <th>2018-tennessee_titans-tampa_bay_buccaneers.txt</th>\n",
       "      <th>2018-washington_redskins-new_england_patriots.txt</th>\n",
       "      <th>2018-washington_redskins-new_york_jets.txt</th>\n",
       "      <th>2018-washington_redskins-philadelphia_eagles-1.txt</th>\n",
       "      <th>2018-washington_redskins-philadelphia_eagles.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teams</th>\n",
       "      <td>[houston_oilers, dallas_texans]</td>\n",
       "      <td>[chicago_bears, green_bay_packers]</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>[new_york_jets, baltimore_colts]</td>\n",
       "      <td>[baltimore_colts, kansas_city_chiefs]</td>\n",
       "      <td>[cleveland_browns, new_york_jets]</td>\n",
       "      <td>[dallas_cowboys, detroit_lions]</td>\n",
       "      <td>[kansas_city_chiefs, baltimore_colts]</td>\n",
       "      <td>[los_angeles_rams, minnesota_vikings]</td>\n",
       "      <td>...</td>\n",
       "      <td>[tampa_bay_buccaneers, dallas_cowboys]</td>\n",
       "      <td>[tampa_bay_buccaneers, detroit_lions]</td>\n",
       "      <td>[tennessee_titans, green_bay_packers]</td>\n",
       "      <td>[tennessee_titans, minnesota_vikings]</td>\n",
       "      <td>[tennessee_titans, pittsburgh_steelers]</td>\n",
       "      <td>[tennessee_titans, tampa_bay_buccaneers]</td>\n",
       "      <td>[washington_redskins, new_england_patriots]</td>\n",
       "      <td>[washington_redskins, new_york_jets]</td>\n",
       "      <td>[washington_redskins, philadelphia_eagles]</td>\n",
       "      <td>[washington_redskins, philadelphia_eagles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcript</th>\n",
       "      <td>gilson well defend the goal on your left theyl...</td>\n",
       "      <td>cbs television sports presents the national fo...</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>&amp;gt;&amp;gt; nbc sports presents the third nflafl ...</td>\n",
       "      <td>biochemistry was almost an that i doing it cam...</td>\n",
       "      <td>from municipal stadium in cleveland ohio to po...</td>\n",
       "      <td>a long time ago ford motor company had a bette...</td>\n",
       "      <td>from memorial stadium in baltimore maryland na...</td>\n",
       "      <td>from metropolitan stadium in bloomington minne...</td>\n",
       "      <td>...</td>\n",
       "      <td>you welcomes you to the following presentation...</td>\n",
       "      <td>well the rain continues to fall but we have fo...</td>\n",
       "      <td>so the first preseason game a couple weeks at ...</td>\n",
       "      <td>time is running out for some opportunity has c...</td>\n",
       "      <td>heinz field and the new head coach of the tita...</td>\n",
       "      <td>tennessee titans preseason football is brought...</td>\n",
       "      <td>the patriots take the field and football retur...</td>\n",
       "      <td>espn welcomes you to the following presentatio...</td>\n",
       "      <td>and there is nick falls the eagle fans at atte...</td>\n",
       "      <td>skins and eagles theyve been division rivals d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1962</td>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        1962-houston_oilers-dallas_texans.txt  \\\n",
       "teams                         [houston_oilers, dallas_texans]   \n",
       "transcript  gilson well defend the goal on your left theyl...   \n",
       "year                                                     1962   \n",
       "\n",
       "                     1969-chicago_bears-green_bay_packers.txt  \\\n",
       "teams                      [chicago_bears, green_bay_packers]   \n",
       "transcript  cbs television sports presents the national fo...   \n",
       "year                                                     1969   \n",
       "\n",
       "                1969-cleveland_browns-minnesota_vikings-1.txt  \\\n",
       "teams                   [cleveland_browns, minnesota_vikings]   \n",
       "transcript  the nfl today brought to you by the foundation...   \n",
       "year                                                     1969   \n",
       "\n",
       "                  1969-cleveland_browns-minnesota_vikings.txt  \\\n",
       "teams                   [cleveland_browns, minnesota_vikings]   \n",
       "transcript  the nfl today brought to you by the foundation...   \n",
       "year                                                     1969   \n",
       "\n",
       "                       1969-new_york_jets-baltimore_colts.txt  \\\n",
       "teams                        [new_york_jets, baltimore_colts]   \n",
       "transcript  &gt;&gt; nbc sports presents the third nflafl ...   \n",
       "year                                                     1969   \n",
       "\n",
       "                  1970-baltimore_colts-kansas_city_chiefs.txt  \\\n",
       "teams                   [baltimore_colts, kansas_city_chiefs]   \n",
       "transcript  biochemistry was almost an that i doing it cam...   \n",
       "year                                                     1970   \n",
       "\n",
       "                      1970-cleveland_browns-new_york_jets.txt  \\\n",
       "teams                       [cleveland_browns, new_york_jets]   \n",
       "transcript  from municipal stadium in cleveland ohio to po...   \n",
       "year                                                     1970   \n",
       "\n",
       "                        1970-dallas_cowboys-detroit_lions.txt  \\\n",
       "teams                         [dallas_cowboys, detroit_lions]   \n",
       "transcript  a long time ago ford motor company had a bette...   \n",
       "year                                                     1970   \n",
       "\n",
       "                  1970-kansas_city_chiefs-baltimore_colts.txt  \\\n",
       "teams                   [kansas_city_chiefs, baltimore_colts]   \n",
       "transcript  from memorial stadium in baltimore maryland na...   \n",
       "year                                                     1970   \n",
       "\n",
       "                1970-los_angeles_rams-minnesota_vikings-1.txt  ...  \\\n",
       "teams                   [los_angeles_rams, minnesota_vikings]  ...   \n",
       "transcript  from metropolitan stadium in bloomington minne...  ...   \n",
       "year                                                     1970  ...   \n",
       "\n",
       "                 2018-tampa_bay_buccaneers-dallas_cowboys.txt  \\\n",
       "teams                  [tampa_bay_buccaneers, dallas_cowboys]   \n",
       "transcript  you welcomes you to the following presentation...   \n",
       "year                                                     2018   \n",
       "\n",
       "                  2018-tampa_bay_buccaneers-detroit_lions.txt  \\\n",
       "teams                   [tampa_bay_buccaneers, detroit_lions]   \n",
       "transcript  well the rain continues to fall but we have fo...   \n",
       "year                                                     2018   \n",
       "\n",
       "                  2018-tennessee_titans-green_bay_packers.txt  \\\n",
       "teams                   [tennessee_titans, green_bay_packers]   \n",
       "transcript  so the first preseason game a couple weeks at ...   \n",
       "year                                                     2018   \n",
       "\n",
       "                  2018-tennessee_titans-minnesota_vikings.txt  \\\n",
       "teams                   [tennessee_titans, minnesota_vikings]   \n",
       "transcript  time is running out for some opportunity has c...   \n",
       "year                                                     2018   \n",
       "\n",
       "                2018-tennessee_titans-pittsburgh_steelers.txt  \\\n",
       "teams                 [tennessee_titans, pittsburgh_steelers]   \n",
       "transcript  heinz field and the new head coach of the tita...   \n",
       "year                                                     2018   \n",
       "\n",
       "               2018-tennessee_titans-tampa_bay_buccaneers.txt  \\\n",
       "teams                [tennessee_titans, tampa_bay_buccaneers]   \n",
       "transcript  tennessee titans preseason football is brought...   \n",
       "year                                                     2018   \n",
       "\n",
       "            2018-washington_redskins-new_england_patriots.txt  \\\n",
       "teams             [washington_redskins, new_england_patriots]   \n",
       "transcript  the patriots take the field and football retur...   \n",
       "year                                                     2018   \n",
       "\n",
       "                   2018-washington_redskins-new_york_jets.txt  \\\n",
       "teams                    [washington_redskins, new_york_jets]   \n",
       "transcript  espn welcomes you to the following presentatio...   \n",
       "year                                                     2018   \n",
       "\n",
       "           2018-washington_redskins-philadelphia_eagles-1.txt  \\\n",
       "teams              [washington_redskins, philadelphia_eagles]   \n",
       "transcript  and there is nick falls the eagle fans at atte...   \n",
       "year                                                     2018   \n",
       "\n",
       "             2018-washington_redskins-philadelphia_eagles.txt  \n",
       "teams              [washington_redskins, philadelphia_eagles]  \n",
       "transcript  skins and eagles theyve been division rivals d...  \n",
       "year                                                     2018  \n",
       "\n",
       "[3 rows x 1455 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     /Users/tommayer/nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('word2vec_sample')\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "\n",
    "wvmodel = KeyedVectors.load_word2vec_format(datapath(word2vec_sample), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43981"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wvmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this dataset has 43,981 games over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1: Preprocess text:\n",
    "- remove punctuation\n",
    "- replace with space \n",
    "- also lowercase \n",
    "- transpose it too (with a few simple pandas operations to keep order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transposed = data.T.reset_index().rename(columns={'index': 'game_id'}) # pd operation\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to each transcript\n",
    "data_transposed['tokens'] = data_transposed['transcript'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>teams</th>\n",
       "      <th>transcript</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-houston_oilers-dallas_texans.txt</td>\n",
       "      <td>[houston_oilers, dallas_texans]</td>\n",
       "      <td>gilson well defend the goal on your left theyl...</td>\n",
       "      <td>1962</td>\n",
       "      <td>[gilson, well, defend, the, goal, on, your, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1969-chicago_bears-green_bay_packers.txt</td>\n",
       "      <td>[chicago_bears, green_bay_packers]</td>\n",
       "      <td>cbs television sports presents the national fo...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[cbs, television, sports, presents, the, natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969-cleveland_browns-minnesota_vikings-1.txt</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[the, nfl, today, brought, to, you, by, the, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969-cleveland_browns-minnesota_vikings.txt</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[the, nfl, today, brought, to, you, by, the, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1969-new_york_jets-baltimore_colts.txt</td>\n",
       "      <td>[new_york_jets, baltimore_colts]</td>\n",
       "      <td>&amp;gt;&amp;gt; nbc sports presents the third nflafl ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[gtgt, nbc, sports, presents, the, third, nfla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         game_id  \\\n",
       "0          1962-houston_oilers-dallas_texans.txt   \n",
       "1       1969-chicago_bears-green_bay_packers.txt   \n",
       "2  1969-cleveland_browns-minnesota_vikings-1.txt   \n",
       "3    1969-cleveland_browns-minnesota_vikings.txt   \n",
       "4         1969-new_york_jets-baltimore_colts.txt   \n",
       "\n",
       "                                   teams  \\\n",
       "0        [houston_oilers, dallas_texans]   \n",
       "1     [chicago_bears, green_bay_packers]   \n",
       "2  [cleveland_browns, minnesota_vikings]   \n",
       "3  [cleveland_browns, minnesota_vikings]   \n",
       "4       [new_york_jets, baltimore_colts]   \n",
       "\n",
       "                                          transcript  year  \\\n",
       "0  gilson well defend the goal on your left theyl...  1962   \n",
       "1  cbs television sports presents the national fo...  1969   \n",
       "2  the nfl today brought to you by the foundation...  1969   \n",
       "3  the nfl today brought to you by the foundation...  1969   \n",
       "4  &gt;&gt; nbc sports presents the third nflafl ...  1969   \n",
       "\n",
       "                                              tokens  \n",
       "0  [gilson, well, defend, the, goal, on, your, le...  \n",
       "1  [cbs, television, sports, presents, the, natio...  \n",
       "2  [the, nfl, today, brought, to, you, by, the, f...  \n",
       "3  [the, nfl, today, brought, to, you, by, the, f...  \n",
       "4  [gtgt, nbc, sports, presents, the, third, nfla...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transposed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a column of tokens that we can use to get the game commentary embeddings.  We also have each game as a different row making it easier to work with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the game commentary embeddings. Essentially, computers can do math much more easily with numbers than with text.  So, we'll convert the text into numbers saving compute with a pretrained model (word2vec that I called wvmodel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embedding(tokens, model):\n",
    "    # Filter tokens to only those in the model's vocabulary\n",
    "    valid_tokens = [token for token in tokens if token in model.key_to_index] # or could \n",
    "    if not valid_tokens:\n",
    "        return np.zeros(model.vector_size)\n",
    "    # Average the word vectors\n",
    "    return np.mean([model[token] for token in valid_tokens], axis=0) # average!\n",
    "\n",
    "# Apply to each game transcript\n",
    "data_transposed['doc_embedding'] = data_transposed['tokens'].apply(\n",
    "    lambda tokens: get_document_embedding(tokens, wvmodel) \n",
    ") # apply the function to each row in my df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have averaged the word embeddings in each document to get a single embedding for the document.  This gets me the 'average' word embedding for each game.  This is a simple yet powerful baseline model.  It can show us the semantic meaning for each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the embedding matrix.  This converts the w2v model, that we are using already, into a matrix that we can use for our model. Then, we build a vocabulary dictionary that we can use to map the words to their corresponding indices.  We cannot forget to add the unknown token to the vocabulary dictionary too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = len(wvmodel['university'])      # we know... it's 300\n",
    "\n",
    "# initialize embedding matrix and word-to-id map:\n",
    "embedding_matrix = np.zeros((len(wvmodel) + 1, EMBEDDING_DIM))\n",
    "vocab_dict = {}\n",
    "\n",
    "# build the embedding matrix and the word-to-id map:\n",
    "for i, word in enumerate(wvmodel.index_to_key):\n",
    "    embedding_vector = wvmodel[word]\n",
    "\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        vocab_dict[word] = i\n",
    "\n",
    "# we can use the last index at the end of the vocab for unknown tokens\n",
    "vocab_dict['[UNK]'] = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43982, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the embedding matrix\n",
    "embedding_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0891758 ,  0.121832  , -0.0671959 ,  0.0477279 , -0.013659  ,\n",
       "       -0.0671959 ,  0.0640559 , -0.0331269 , -0.0364239 ,  0.00565199,\n",
       "       -0.017113  , -0.10362   ,  0.0552639 , -0.00706499, -0.0643699 ,\n",
       "        0.00753598, -0.0866638 ,  0.0492979 , -0.0816398 , -0.0910598 ,\n",
       "        0.00416049, -0.0681379 ,  0.0568339 ,  0.0524379 ,  0.00143262,\n",
       "       -0.01256   , -0.0775578 ,  0.0960838 ,  0.0555779 , -0.0734758 ,\n",
       "       -0.013659  , -0.0376799 , -0.0489839 , -0.0470999 , -0.102992  ,\n",
       "        0.00612299,  0.0452159 , -0.0356389 ,  0.0665679 ,  0.0747318 ,\n",
       "        0.0759878 , -0.0248059 ,  0.013031  , -0.00490624,  0.00733973,\n",
       "       -0.0351679 ,  0.00639774, -0.00370912,  0.0835238 ,  0.0477279 ,\n",
       "       -0.0885478 , -0.0929438 ,  0.0634279 ,  0.0741038 ,  0.00561274,\n",
       "       -0.0192325 ,  0.0803838 ,  0.00580899,  0.0923158 ,  0.0700219 ,\n",
       "        0.0266899 ,  0.0788138 , -0.0634279 , -0.0470999 ,  0.0835238 ,\n",
       "       -0.0483559 ,  0.0574619 ,  0.0411339 ,  0.00455299,  0.0712778 ,\n",
       "        0.0769298 , -0.0173485 , -0.10676   , -0.0343829 ,  0.00134431,\n",
       "        0.0753598 , -0.00470999, -0.0584039 ,  0.0967118 ,  0.0467859 ,\n",
       "       -0.010519  , -0.0279459 ,  0.0265329 , -0.013659  , -0.14444   ,\n",
       "        0.0430179 ,  0.0778718 , -0.0558919 , -0.0285739 , -0.021352  ,\n",
       "       -0.0430179 ,  0.0665679 , -0.0508679 ,  0.0543219 , -0.0323419 ,\n",
       "       -0.1099    ,  0.0365809 , -0.00549499, -0.012403  , -0.158884  ,\n",
       "        0.0400349 , -0.11618   ,  0.105504  , -0.0898038 ,  0.010676  ,\n",
       "       -0.0477279 , -0.0345399 , -0.0324989 ,  0.00347362, -0.0241779 ,\n",
       "       -0.0458439 ,  0.0323419 ,  0.0659399 ,  0.0693939 ,  0.0659399 ,\n",
       "       -0.0361099 ,  0.0346969 , -0.114296  , -0.118064  ,  0.0268469 ,\n",
       "       -0.0470999 ,  0.020253  , -0.013188  , -0.0383079 , -0.023864  ,\n",
       "        0.0719059 ,  0.0697079 ,  0.0847798 ,  0.0910598 , -0.0244919 ,\n",
       "       -0.00859573,  0.0365809 ,  0.013345  ,  0.0756738 , -0.0414479 ,\n",
       "        0.00506324, -0.0102835 ,  0.0430179 ,  0.0904318 ,  0.0653119 ,\n",
       "        0.0602879 , -0.0562059 , -0.0246489 ,  0.020567  ,  0.0784998 ,\n",
       "        0.0954558 , -0.0274749 ,  0.0753598 ,  0.00938073, -0.0973398 ,\n",
       "        0.0788138 ,  0.019311  , -0.016485  ,  0.0496119 , -0.012089  ,\n",
       "       -0.00135412, -0.0394069 ,  0.0593459 , -0.0176625 ,  0.0521239 ,\n",
       "       -0.0731618 ,  0.0255909 ,  0.020253  , -0.0401919 , -0.00266899,\n",
       "       -0.0728479 , -0.0290449 ,  0.00304187,  0.00107447,  0.0518099 ,\n",
       "       -0.0120105 , -0.0392499 , -0.022765  ,  0.00651549, -0.0427039 ,\n",
       "       -0.0449019 ,  0.0649979 ,  0.0102835 , -0.0967118 , -0.0390929 ,\n",
       "       -0.148836  , -0.118692  ,  0.0602879 ,  0.0126385 , -0.0464719 ,\n",
       "        0.0271609 , -0.0778718 , -0.0587179 , -0.013816  ,  0.0524379 ,\n",
       "        0.0417619 , -0.133764  ,  0.0373659 , -0.01413   ,  0.101736  ,\n",
       "        0.111784  ,  0.021195  ,  0.0433319 ,  0.0240209 ,  0.101736  ,\n",
       "       -0.0527519 , -0.021823  , -0.0284169 , -0.0276319 , -0.00098615,\n",
       "       -0.016014  , -0.0149935 ,  0.0998518 ,  0.0712778 , -0.0470999 ,\n",
       "       -0.0279459 , -0.0387789 , -0.00170737, -0.0609159 , -0.0979678 ,\n",
       "        0.0483559 ,  0.0340689 , -0.138788  ,  0.0439599 , -0.0342259 ,\n",
       "        0.011775  ,  0.00761448,  0.00922373, -0.0173485 ,  0.0458439 ,\n",
       "       -0.0584039 ,  0.00608374, -0.00522024,  0.0178195 , -0.016171  ,\n",
       "        0.00604449, -0.0898038 , -0.020567  ,  0.013973  ,  0.0527519 ,\n",
       "       -0.016014  ,  0.0127955 , -0.0271609 ,  0.0401919 ,  0.0397209 ,\n",
       "       -0.00710424, -0.0656259 ,  0.01256   , -0.0847798 , -0.0442739 ,\n",
       "        0.0339119 ,  0.0401919 ,  0.014915  , -0.0637419 ,  0.0290449 ,\n",
       "       -0.0179765 ,  0.0251199 , -0.0615439 ,  0.0499259 ,  0.0164065 ,\n",
       "        0.0386219 , -0.0609159 ,  0.0800698 , -0.0822678 ,  0.0310859 ,\n",
       "       -0.0788138 , -0.00663324,  0.0127955 ,  0.020567  ,  0.0835238 ,\n",
       "        0.110528  , -0.108644  ,  0.00374837, -0.020567  , -0.0464719 ,\n",
       "       -0.015386  ,  0.0979678 , -0.023864  , -0.012717  ,  0.0251199 ,\n",
       "       -0.0389359 ,  0.0828958 ,  0.10676   ,  0.0390929 ,  0.0756738 ,\n",
       "        0.0140515 , -0.021823  ,  0.16202401,  0.0941998 , -0.0118535 ,\n",
       "       -0.0452159 , -0.0298299 ,  0.0423899 ,  0.0712778 ,  0.00241387,\n",
       "       -0.00883123,  0.0577759 , -0.0189185 ,  0.0168775 ,  0.0408199 ,\n",
       "       -0.0405059 ,  0.0552639 , -0.0480419 , -0.0277889 ,  0.0872918 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and take a look at the first embedding vector, a game from 1962!\n",
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Which broadcast was each game on? Search and add the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to identiy the TV network broadcast in which each game takes place.  By network contract, the commentators must present the network names during the broadcast.  I will search the for the broacast in the tokenized game transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the channels that broadcast NFL games\n",
    "channels = ['NBC', 'CBS', 'ESPN', 'FOX', 'ABC', 'NFL Network']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Simple Channel Mention Model\n",
    "I will start with a simple method for extracting the channel.  When broadcasting the game, the commentators must present the channel multiple times promoting which station is in charge of the game's presentation.  This model merely counts the mentions of the possibile broadcasts and labels the game with the highest mentioned channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network distribution:\n",
      "broadcaster\n",
      "ESPN             397\n",
      "FOX              291\n",
      "CBS              263\n",
      "Unknown          220\n",
      "ABC              166\n",
      "NBC               99\n",
      "Tie: ESPN/ABC     10\n",
      "Tie: FOX/ESPN      4\n",
      "Tie: FOX/NBC       2\n",
      "Tie: NBC/ESPN      1\n",
      "Tie: FOX/ABC       1\n",
      "Tie: CBS/NBC       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Network distribution by year:\n",
      "broadcaster  ABC  CBS  ESPN  FOX  NBC  Tie: CBS/NBC  Tie: ESPN/ABC  \\\n",
      "year                                                                 \n",
      "1962           1    0     0    0    0             0              0   \n",
      "1969           0    3     0    0    1             0              0   \n",
      "1970           7    1     0    0    0             0              0   \n",
      "1971           8    0     1    1    1             0              0   \n",
      "1972           4    3     0    0    2             0              0   \n",
      "1973           3    0     0    0    3             0              0   \n",
      "1974           2    0     0    2    1             0              0   \n",
      "1975           3    0     0    0    2             0              0   \n",
      "1976           7    3     0    5    7             0              0   \n",
      "1977           1    0     0    0    2             0              0   \n",
      "1978           1    2     0    0    1             0              0   \n",
      "1979           6    1     0    0    8             0              0   \n",
      "1980           1    1     1    0    0             0              0   \n",
      "1981           0    1     0    0    4             0              0   \n",
      "1982           1    1     1    0    0             0              0   \n",
      "1983           2    2     0    1    1             0              0   \n",
      "1984           3    5     2    2    0             0              0   \n",
      "1985           6    3     0    0    0             0              0   \n",
      "1986           1    0     0    0    1             0              0   \n",
      "1987           0    6     4    0    1             0              0   \n",
      "1988           3    4     3    0    1             0              1   \n",
      "1989           2    6     1    0    1             0              0   \n",
      "1990           0    2     2    0    0             0              0   \n",
      "1991           3    2     0    1    2             0              0   \n",
      "1992           3    0     0    0    3             0              0   \n",
      "1993           2    1     0    1    4             0              0   \n",
      "1994           7    0     3    4    2             0              0   \n",
      "1995           3    1     5    5    1             0              0   \n",
      "1996           4    2     7    6    3             0              0   \n",
      "1997           3    1     6    2    2             0              0   \n",
      "1998           5    8     5    4    0             0              0   \n",
      "1999           4    1     2    4    0             0              0   \n",
      "2000           3    1     3    3    1             0              0   \n",
      "2001           1    8     2    3    1             0              0   \n",
      "2002           4    3     6    6    0             0              0   \n",
      "2003           3    5     5    4    0             0              0   \n",
      "2004           4    4     4    0    0             0              0   \n",
      "2005           5    5     6    7    0             0              0   \n",
      "2006           6    2    18   11    3             0              0   \n",
      "2007           6    2    15    4    1             0              1   \n",
      "2008           7    9    18    9    2             0              0   \n",
      "2009           9    4    12   11    4             0              0   \n",
      "2010           3   13    20   13    1             0              0   \n",
      "2011           4   19    34   12    4             0              3   \n",
      "2012           0    6     1    4    2             0              1   \n",
      "2013           4   18    31   17    2             0              2   \n",
      "2014           0    6    50   24    3             0              1   \n",
      "2015           1   18    45   16    3             0              0   \n",
      "2016           7   52    73   61   11             1              1   \n",
      "2017           0    1     2    1    0             0              0   \n",
      "2018           3   27     9   47    7             0              0   \n",
      "\n",
      "broadcaster  Tie: FOX/ABC  Tie: FOX/ESPN  Tie: FOX/NBC  Tie: NBC/ESPN  Unknown  \n",
      "year                                                                            \n",
      "1962                    0              0             0              0        0  \n",
      "1969                    0              0             0              0        0  \n",
      "1970                    0              0             0              0        0  \n",
      "1971                    0              0             0              0        0  \n",
      "1972                    0              0             0              0        0  \n",
      "1973                    0              0             0              0        0  \n",
      "1974                    0              0             0              0        0  \n",
      "1975                    0              0             0              0        6  \n",
      "1976                    0              0             0              0        1  \n",
      "1977                    0              0             0              0        5  \n",
      "1978                    0              0             0              0        1  \n",
      "1979                    0              0             0              0        2  \n",
      "1980                    0              0             0              0        3  \n",
      "1981                    0              0             0              0        2  \n",
      "1982                    0              0             0              0        4  \n",
      "1983                    0              0             0              0        4  \n",
      "1984                    0              0             0              0        6  \n",
      "1985                    0              0             0              0        4  \n",
      "1986                    0              0             0              0        2  \n",
      "1987                    0              0             0              0        5  \n",
      "1988                    0              0             0              0        6  \n",
      "1989                    0              0             0              0        3  \n",
      "1990                    0              0             0              1        3  \n",
      "1991                    0              0             0              0        5  \n",
      "1992                    0              0             0              0        2  \n",
      "1993                    0              0             0              0        0  \n",
      "1994                    0              0             0              0        4  \n",
      "1995                    0              0             0              0        5  \n",
      "1996                    0              0             0              0        6  \n",
      "1997                    0              0             0              0        5  \n",
      "1998                    0              0             0              0        3  \n",
      "1999                    0              0             0              0        3  \n",
      "2000                    0              1             0              0        1  \n",
      "2001                    1              0             0              0        0  \n",
      "2002                    0              0             0              0        1  \n",
      "2003                    0              0             0              0        1  \n",
      "2004                    0              0             0              0        2  \n",
      "2005                    0              0             0              0        2  \n",
      "2006                    0              0             0              0       16  \n",
      "2007                    0              0             0              0        3  \n",
      "2008                    0              0             0              0        6  \n",
      "2009                    0              0             0              0       14  \n",
      "2010                    0              0             0              0        6  \n",
      "2011                    0              0             0              0       11  \n",
      "2012                    0              0             0              0        0  \n",
      "2013                    0              1             0              0        6  \n",
      "2014                    0              0             0              0       13  \n",
      "2015                    0              0             1              0       13  \n",
      "2016                    0              2             0              0       12  \n",
      "2017                    0              0             0              0        2  \n",
      "2018                    0              0             1              0       21  \n"
     ]
    }
   ],
   "source": [
    "def get_most_mentioned_network(transcript):\n",
    "    networks = {\n",
    "        'CBS': transcript.upper().count('CBS'),\n",
    "        'FOX': transcript.upper().count('FOX'),\n",
    "        'NBC': transcript.upper().count('NBC'),\n",
    "        'ESPN': transcript.upper().count('ESPN'),\n",
    "        'ABC': transcript.upper().count('ABC')\n",
    "    } # counts the mentions of each network (upper case though)\n",
    "    \n",
    "    # get the max of the networks\n",
    "    most_mentioned = max(networks.items(), key=lambda x: x[1])\n",
    "\n",
    "    # edge case: tie\n",
    "    # Check if there's a tie (multiple networks with the same highest count)\n",
    "    max_count = most_mentioned[1]\n",
    "    if max_count == 0:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Find all networks with the max count\n",
    "    tied_networks = [network for network, count in networks.items() if count == max_count]\n",
    "    if len(tied_networks) > 1:\n",
    "        return 'Tie: ' + '/'.join(tied_networks)\n",
    "    \n",
    "    # edge case for when NO network was mentioned\n",
    "    if most_mentioned[1] > 0:\n",
    "        return most_mentioned[0]\n",
    "    return 'Unknown'\n",
    "\n",
    "# now add the broadcaster to the df as simple model (will compare outputs later)\n",
    "data_transposed['broadcaster_simpleModel'] = data_transposed['transcript'].apply(get_most_mentioned_network)\n",
    "\n",
    "# show the distribution as well\n",
    "print(\"Network distribution:\")\n",
    "print(data_transposed['broadcaster'].value_counts())\n",
    "\n",
    "# group it by year and broadcaster to see if it makes sense\n",
    "print(\"\\nNetwork distribution by year:\")\n",
    "yearly_distribution = data_transposed.groupby(['year', 'broadcaster']).size().unstack(fill_value=0)\n",
    "print(yearly_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>teams</th>\n",
       "      <th>transcript</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "      <th>doc_embedding</th>\n",
       "      <th>broadcaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-houston_oilers-dallas_texans.txt</td>\n",
       "      <td>[houston_oilers, dallas_texans]</td>\n",
       "      <td>gilson well defend the goal on your left theyl...</td>\n",
       "      <td>1962</td>\n",
       "      <td>[gilson, well, defend, the, goal, on, your, le...</td>\n",
       "      <td>[0.02728455, 0.016727475, 0.0260244, 0.0380681...</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1969-chicago_bears-green_bay_packers.txt</td>\n",
       "      <td>[chicago_bears, green_bay_packers]</td>\n",
       "      <td>cbs television sports presents the national fo...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[cbs, television, sports, presents, the, natio...</td>\n",
       "      <td>[0.030220592, 0.014963325, 0.02284711, 0.03831...</td>\n",
       "      <td>CBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969-cleveland_browns-minnesota_vikings-1.txt</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[the, nfl, today, brought, to, you, by, the, f...</td>\n",
       "      <td>[0.027876755, 0.016259313, 0.022658505, 0.0399...</td>\n",
       "      <td>CBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969-cleveland_browns-minnesota_vikings.txt</td>\n",
       "      <td>[cleveland_browns, minnesota_vikings]</td>\n",
       "      <td>the nfl today brought to you by the foundation...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[the, nfl, today, brought, to, you, by, the, f...</td>\n",
       "      <td>[0.028167814, 0.016339412, 0.022509856, 0.0396...</td>\n",
       "      <td>CBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1969-new_york_jets-baltimore_colts.txt</td>\n",
       "      <td>[new_york_jets, baltimore_colts]</td>\n",
       "      <td>&amp;gt;&amp;gt; nbc sports presents the third nflafl ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>[gtgt, nbc, sports, presents, the, third, nfla...</td>\n",
       "      <td>[0.031091398, 0.015320361, 0.02407883, 0.03909...</td>\n",
       "      <td>NBC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         game_id  \\\n",
       "0          1962-houston_oilers-dallas_texans.txt   \n",
       "1       1969-chicago_bears-green_bay_packers.txt   \n",
       "2  1969-cleveland_browns-minnesota_vikings-1.txt   \n",
       "3    1969-cleveland_browns-minnesota_vikings.txt   \n",
       "4         1969-new_york_jets-baltimore_colts.txt   \n",
       "\n",
       "                                   teams  \\\n",
       "0        [houston_oilers, dallas_texans]   \n",
       "1     [chicago_bears, green_bay_packers]   \n",
       "2  [cleveland_browns, minnesota_vikings]   \n",
       "3  [cleveland_browns, minnesota_vikings]   \n",
       "4       [new_york_jets, baltimore_colts]   \n",
       "\n",
       "                                          transcript  year  \\\n",
       "0  gilson well defend the goal on your left theyl...  1962   \n",
       "1  cbs television sports presents the national fo...  1969   \n",
       "2  the nfl today brought to you by the foundation...  1969   \n",
       "3  the nfl today brought to you by the foundation...  1969   \n",
       "4  &gt;&gt; nbc sports presents the third nflafl ...  1969   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [gilson, well, defend, the, goal, on, your, le...   \n",
       "1  [cbs, television, sports, presents, the, natio...   \n",
       "2  [the, nfl, today, brought, to, you, by, the, f...   \n",
       "3  [the, nfl, today, brought, to, you, by, the, f...   \n",
       "4  [gtgt, nbc, sports, presents, the, third, nfla...   \n",
       "\n",
       "                                       doc_embedding broadcaster  \n",
       "0  [0.02728455, 0.016727475, 0.0260244, 0.0380681...         ABC  \n",
       "1  [0.030220592, 0.014963325, 0.02284711, 0.03831...         CBS  \n",
       "2  [0.027876755, 0.016259313, 0.022658505, 0.0399...         CBS  \n",
       "3  [0.028167814, 0.016339412, 0.022509856, 0.0396...         CBS  \n",
       "4  [0.031091398, 0.015320361, 0.02407883, 0.03909...         NBC  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where we started:\n",
    "A dataset with unique game ids as a header, the transcript, the teams, and the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where the data is now:\n",
    "A unique game id columns, the two teams, a tokenized transcript with NLP preprocessing tactics implemented, document embeddings for each word, and the broadcast of each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
